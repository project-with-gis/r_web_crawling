from dateutil.parser import parse
import re
import os
import datetime
import pandas as pd
from hanspell import spell_checker
from soynlp.normalizer import *

# íŠ¹ì •í–‰ì„ ê¸°ì¤€ìœ¼ë¡œ nullê°’ì´ ìˆìœ¼ë©´ í•´ë‹¹ í–‰ì„ ì‚­ì œ
def remove_nan(df,subset):
    df.dropna(subset=subset, inplace=True)
    df = df.reset_index(drop=True)
    return df

# ì „ì²˜ë¦¬ í›„ ''ë¦¬ë·°ê°€ ë¹„ì–´ìˆëŠ” í–‰ ì‚­ì œ
def remove_after_nan(total_review):
    for i, after_review in enumerate(total_review['preprocessed_review']):
        if after_review == '':
            total_review.drop(index=i, inplace=True)
    total_review.reset_index(drop=True)
    return total_review

# ì‹ì‹  ì‚¬ì´íŠ¸ date í˜•ì‹ë³€í™˜
def siksin_transform_datetime_df(df, int):
    date = df.iloc[:, int].astype(str)
    date = date.str.split(" ")
    df.iloc[:, int] = date.str.get(0)
    return df

# ë„¤ì´ë²„ì‚¬ì´íŠ¸ date í˜•ì‹ë³€í™˜
def naver_transform_datetime_df(df):
    # ìš”ì¼ ì œê±°
    for i, line in enumerate(df['date']):
        line = line.rstrip('.ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼')
        df['date'][i] = line
    # ë‚ ì§œ ë³€í™˜
    for i in range(len(df)):
      a = parse(df['date'][i], yearfirst=True)
      df['date'][i] = a.strftime("%Y-%m-%d")

# êµ¬ê¸€ ì‚¬ì´íŠ¸ í•œê¸€ì„ ì˜ì–´ë¡œ ë²ˆì—­í•œ ì˜ì–´ë¶€ë¶„ ì œê±°
def google_eng_transfer_del1(google_review_data):
    print(len(google_review_data))
    for i, review in enumerate(google_review_data['review']):
        if type(review) != 'str':
            review = str(review)
        if "Google ë²ˆì—­ ì œê³µ" in review:
            print(review)
            google_review_data.drop(index=i, inplace=True)
            print(len(google_review_data))
    google_review_data.reset_index(drop=True)
    return google_review_data

# êµ¬ê¸€ ì‚¬ì´íŠ¸ ì˜ì–´ë²ˆì—­ë¶€ë¶„ì œê±° í•œê¸€ë§Œ ì¶”ì¶œ -> ì „ì²˜ë¦¬ì—ì„œ ë‹¤ì‹œ ì œëŒ€ë¡œ ì œê±°ë¨
def google_eng_transfer_del2(google_review_data):
    print(google_review_data)
    reviewlist=[]
    for review in google_review_data:
        if "Translated by Google" in review:
            # print(review)
            if "Original" in review:
                search = "O"
                indexNo = review.find(search)
                new = review[indexNo:]
                reviewlist.append(new)
                print(new)
            else:
                # "Original" not in review:
                search = "T"
                indexNo = review.find(search)
                new = review[:indexNo]
                reviewlist.append(new)
                print(new)
        else:
            reviewlist.append(review)
    print(len(reviewlist))
    return reviewlist



# def swap_columns_with_name_df(df, *args): # (*args)ì—ëŠ” ì›í•˜ëŠ” columns ì´ë¦„ ìˆœì„œëŒ€ë¡œ(ë”°ì˜´í‘œ ìŠì§€ë§ê¸°)
#     df = df[[*args]]
#     # print(df.head())
#     return df

# ì»¬ëŸ¼ìœ„ì¹˜ì¡°ì •
def swap_columns_with_num_df(df, *args): # (*args)ì—ëŠ” ì›í•˜ëŠ” columns indexìˆœì„œëŒ€ë¡œ
    col = df.columns.to_numpy()
    col = col[[*args]]
    df = df[col]
    # print(df.head())
    return df

# í‰ì  ë°˜ì˜¬ë¦¼í•´ì£¼ëŠ” í•¨ìˆ˜
def rounding_off_scores_df(df, num):
    num = int(num)
    score = df.iloc[:, num]
    df.iloc[:, num] = score.round(0).astype(int)
    # print(df.iloc[:, num].head(21))
    return df


#######################ê³µí†µìœ¼ë¡œì“°ëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜###########################
# ì „ì²˜ë¦¬ê³¼ì • ì „ë¶€ ì§„í–‰í•˜ëŠ” í•¨ìˆ˜
# ë¦¬ë·°í•˜ë‚˜ê°€ ì „ì²´ ì „ì²˜ë¦¬ê³¼ì •ì„ ëŒê³  -> ë¦¬ìŠ¤íŠ¸ì— ì „ì²˜ë¦¬ í›„ ë¦¬ë·°ë“¤ì´ í•˜ë‚˜ì”© ë¦¬ìŠ¤íŠ¸ì— ë‹´ê¸´ë‹¤
def prepro(review_list,df):
    after_review_total = []

    for i, one_review in enumerate(review_list):
        try:
            print(i, "=======================================")
            print(one_review)
            after_basic_check = basic_check(one_review)
            print(after_basic_check)
            after_spell_check = spell_check_text(after_basic_check)
            print(after_spell_check)
            after_review_total.append(after_spell_check)
        except:
            print("pass")
            df.drop(index=i, inplace=True)

    df.reset_index(drop=True)
    return after_review_total, df


# ê°€ì¥ ê¸°ì´ˆì ì¸ ì „ì²˜ë¦¬
# html tag ì œê±°
# ìˆ«ì ì œê±°
# Lowercasing
# "@%*=()/+ ì™€ ê°™ì€ punctuation ì œê±°
def basic_check(review):  # í•œ í–‰ë§ˆë‹¤ ì‹¤í–‰ë˜ë„ë¡. ì´ í•¨ìˆ˜ê°€ ë°›ì•„ì˜¤ëŠ”ê±´ í•˜ë‚˜ì˜ ë¦¬ë·°
    cleaned_corpus = clean_punc(review)
    basic_preprocessed_corpus = clean_text(cleaned_corpus)
    return basic_preprocessed_corpus

# ì‚¬ì „ ê¸°ë°˜ì˜ ì˜¤íƒˆì êµì •
# ì¤„ì„ë§ ì›í˜• ë³µì› (e.g. I'm not happy -> I am not happy)
def spell_check_text(texts): # í•œ ëŒ“ê¸€ì— ëŒ€í•œ ë¬¸ì¥ë“¤
    lownword_map = make_dictionary() # ì™¸ë˜ì–´ ì‚¬ì „
    spelled_sent = spell_checker.check(texts) # ë„ì–´ì“°ê¸°, ë§ì¶¤ë²•
    checked_sent = spelled_sent.checked
    normalized_sent = repeat_normalize(checked_sent) # ë°˜ë³µë˜ëŠ” ì´ëª¨í‹°ì½˜ì´ë‚˜ ìëª¨ë¥¼ normalization
    for lownword in lownword_map: # ì™¸ë˜ì–´ ë°”ê¿”ì¤Œ (miss spell -> origin spell)
        normalized_sent = normalized_sent.replace(lownword, lownword_map[lownword])
    corpus = normalized_sent

    return corpus

def make_dictionary():
    lownword_map = {}
    lownword_data = open('data/confused_loanwords.txt', 'r', encoding='utf-8')
    lines = lownword_data.readlines()
    for line in lines:
        line = line.strip()
        miss_spell = line.split('\t')[0]
        ori_word = line.split('\t')[1]
        lownword_map[miss_spell] = ori_word
    return lownword_map

def clean_punc(texts): #ë¬¸ì¥ë¶€í˜¸ê°™ì€ê±° ë‹¤ ì‚­ì œ
    punct = "/-'?!.,#$%\'()*+-/:;<=>@[\\]^_`{|}~" + '""â€œâ€â€™' + 'âˆÎ¸Ã·Î±â€¢Ã âˆ’Î²âˆ…Â³Ï€â€˜â‚¹Â´Â°Â£â‚¬\Ã—â„¢âˆšÂ²â€”â€“&'

    punct_mapping = {"â€˜": "'", "â‚¹": "e", "Â´": "'", "Â°": "", "â‚¬": "e", "â„¢": "tm", "âˆš": " sqrt ", "Ã—": "x", "Â²": "2",
                     "â€”": "-", "â€“": "-", "â€™": "'", "_": "-", "`": "'", 'â€œ': '"', 'â€': '"', 'â€œ': '"', "Â£": "e",
                     'âˆ': 'infinity', 'Î¸': 'theta', 'Ã·': '/', 'Î±': 'alpha', 'â€¢': '.', 'Ã ': 'a', 'âˆ’': '-', 'Î²': 'beta',
                     'âˆ…': '', 'Â³': '3', 'Ï€': 'pi', }

    for p in punct_mapping:
        texts = texts.replace(p, punct_mapping[p])  # punct_mappingì— ìˆëŠ” ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ëŒ€ì‘ë˜ëŠ”ê±¸ë¡œ ë³€ê²½ë˜ë„ë¡ í•œë‹¤.

    for p in punct:
        texts = texts.replace(p, f' {p} ')

    specials = {'\u200b': ' ', 'â€¦': ' ... ', '\ufeff': '', 'à¤•à¤°à¤¨à¤¾': '', 'à¤¹à¥ˆ': '', '\r': ''} # ëŒ€ì²´í•˜ê³ ì‹¶ì€ê±° ì•Œì•„ì„œ ì¶”ê°€í•˜ê¸°
    for s in specials:
        texts = texts.replace(s, specials[s])
    texts = texts.strip() #ë¹ˆì¹¸ ì‚­ì œ

    return texts

def clean_text(line):
    emoji_pattern = re.compile("["
            u"\U0001F600-\U0001F64F"  # emoticons
            u"\U0001F300-\U0001F5FF"  # symbols & pictographs
            u"\U0001F680-\U0001F6FF"  # transport & map symbols
            u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                               "]+", flags=re.UNICODE)
    review = re.sub(r'[@%\*=()/~#&\+Ã¡?\xc3\xa1\|\.\:\;\!\,\_\~\$\'\"\(\)\â™¥\â­\â™¡\â˜†\â˜…\ã…‹\ã… \ã…œ\ã„±\ã…\ã„²\ã…¡\?\^\!\-\á†¢\>\<\ã†]', '',str(line)) #remove punctuation
    # review = re.sub(r'\d+','', review)# remove number# remove number
    # review = review.lower() #lower case
    # review = re.sub(r'[à©­ Ë™á—œË™ à©­âœ§ Ì€ Ì« Ìâœ§ â¤â˜º<ğŸ§€ğŸ¥°â£ğŸ§¡â¬†â¬‡[] Â¤Ì´Ì¶Ì·Ì¤Ì â€§Ì«Ì® Â¤Ì´Ì¶Ì·Ì¤Ì€ â˜˜ã€° ğŸ¤¤â˜•â—¡Ìˆâ™€â¡â¬…â˜ºğŸ¤™â€â™‚ï¸â€âœ¨â˜€ğŸ¥³ à²¥ à¡‡ à²¥  ËƒÌ¶á·„â€§Ì« Ë‚Ì¶á·…à¹‘ âœ‹ á•• á› á•— ğŸ¦‘ â—¡ Ù© á› ÙˆğŸ¤— ] â›° à·† à·† ğŸ¥˜ğŸ§š]', '', review)
    review = re.sub(r'~', 'ì—ì„œ', review)  #50~60ëŒ€ ì—ì„œ ~
    review = re.sub(r'[ã„±-ã…ã…-ã…£]', '', review)  # í•œê¸€ ã…ã…,ã…œ,ã…£ ë“± ì˜¤íƒˆì ì œê±°
    review = re.sub(r'[a-zA-Z]', '', review) #ì˜ì–´ ì œê±°
    review = re.sub(r'\s+', ' ', review) #remove extra space
    review = re.sub(r'<[^>]+>','',review) #remove Html tags
    review = re.sub(r'\s+', ' ', review) #remove spaces
    review = re.sub(r"^\s+", '', review) #remove space from start
    review = re.sub(r'\s+$', '', review) #remove space from the end
    review = emoticon_normalize(review, num_repeats=2) #í•˜í•˜, ì´ëª¨í‹°ì½˜ ë“± ì œê±°
    review = emoji_pattern.sub(r'', review) #ì´ëª¨ì§€ ì œê±°

    return review

